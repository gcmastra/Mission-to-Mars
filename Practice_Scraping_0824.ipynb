{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b330bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to add this file name to the .gitignore later \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3dd877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 92.0.4515\n",
      "Get LATEST driver version for 92.0.4515\n",
      "There is no [win32] chromedriver for browser 92.0.4515 in cache\n",
      "Get LATEST driver version for 92.0.4515\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/92.0.4515.107/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\Christopher\\.wdm\\drivers\\chromedriver\\win32\\92.0.4515.107]\n"
     ]
    }
   ],
   "source": [
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02508ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Quotes to Scrape site\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf675034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb09065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top Ten tags'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the Title\n",
    "title = html_soup.find('h2').text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b143ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "inspirational\n",
      "life\n",
      "humor\n",
      "books\n",
      "reading\n",
      "friendship\n",
      "friends\n",
      "truth\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "# Scrape the top ten tags\n",
    "tag_box = html_soup.find('div', class_='tags-box')\n",
    "# tag_box\n",
    "tags = tag_box.find_all('a', class_='tag')\n",
    "\n",
    "for tag in tags:\n",
    "    word = tag.text\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43149bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICE scraping http://books.toscrape.com/\n",
    "# Visit the Quotes to Scrape site\n",
    "url = 'http://books.toscrape.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "# Parse the HTML\n",
    "html = browser.html\n",
    "html_soup = soup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a0d92cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Light in the Attic - URL = catalogue/a-light-in-the-attic_1000/index.html\n",
      "-----\n",
      "Tipping the Velvet - URL = catalogue/tipping-the-velvet_999/index.html\n",
      "-----\n",
      "Soumission - URL = catalogue/soumission_998/index.html\n",
      "-----\n",
      "Sharp Objects - URL = catalogue/sharp-objects_997/index.html\n",
      "-----\n",
      "Sapiens: A Brief History of Humankind - URL = catalogue/sapiens-a-brief-history-of-humankind_996/index.html\n",
      "-----\n",
      "The Requiem Red - URL = catalogue/the-requiem-red_995/index.html\n",
      "-----\n",
      "The Dirty Little Secrets of Getting Your Dream Job - URL = catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\n",
      "-----\n",
      "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull - URL = catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\n",
      "-----\n",
      "The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics - URL = catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\n",
      "-----\n",
      "The Black Maria - URL = catalogue/the-black-maria_991/index.html\n",
      "-----\n",
      "Starving Hearts (Triangular Trade Trilogy, #1) - URL = catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\n",
      "-----\n",
      "Shakespeare's Sonnets - URL = catalogue/shakespeares-sonnets_989/index.html\n",
      "-----\n",
      "Set Me Free - URL = catalogue/set-me-free_988/index.html\n",
      "-----\n",
      "Scott Pilgrim's Precious Little Life (Scott Pilgrim #1) - URL = catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\n",
      "-----\n",
      "Rip it Up and Start Again - URL = catalogue/rip-it-up-and-start-again_986/index.html\n",
      "-----\n",
      "Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991 - URL = catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\n",
      "-----\n",
      "Olio - URL = catalogue/olio_984/index.html\n",
      "-----\n",
      "Mesaerion: The Best Science Fiction Stories 1800-1849 - URL = catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\n",
      "-----\n",
      "Libertarianism for Beginners - URL = catalogue/libertarianism-for-beginners_982/index.html\n",
      "-----\n",
      "It's Only the Himalayas - URL = catalogue/its-only-the-himalayas_981/index.html\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Scrape the Title\n",
    "title = html_soup.find('a').text\n",
    "# title\n",
    "\n",
    "big_box = html_soup.find('ol', class_='row')\n",
    "articles = big_box.find_all('a')\n",
    "\n",
    "for article in articles:\n",
    "    word_dict = article.attrs\n",
    "    word = word_dict['href']\n",
    "    # word2 = word_dict['title']\n",
    "    word2 = article.attrs\n",
    "    if ('title' in word_dict):\n",
    "        print(word_dict['title'] +  ' - URL = ' + word)\n",
    "        print('-----')\n",
    "        \n",
    "\n",
    "\n",
    "# this works or looks like it worked except every other row is blankn because they are graphics tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d9c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
